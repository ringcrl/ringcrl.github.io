---
layout: post
title: WebCodecså¯¹éŸ³è§†é¢‘è¿›è¡Œç¼–ç è§£ç 
tags: ['2020']
comments: true
---

# WebCodecs

- è‰æ¡ˆï¼šhttps://wicg.github.io/web-codecs/
- Githubï¼šhttps://github.com/WICG/web-codecs

å…è®¸ Web åº”ç”¨ç¨‹åºå¯¹éŸ³é¢‘å’Œè§†é¢‘è¿›è¡Œç¼–ç å’Œè§£ç çš„ API


# åœ¨ Chrome >= 86 çš„ç‰ˆæœ¬è¿›è¡Œä½“éªŒ

- Chromeåœ°å€æ è¾“å…¥ï¼šchrome://flags/#enable-experimental-web-platform-featuresï¼Œè®¾ç½®æˆ `Enabled`
- é€šè¿‡å‘½ä»¤è¡Œå¯ç”¨ Chromeï¼š`/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --enable-blink-features=WebCodecs`

```js
// é€šè¿‡ VideoEncoder API æ£€æŸ¥å½“å‰æµè§ˆå™¨æ˜¯å¦æ”¯æŒ
if ('VideoEncoder' in window) {
  // æ”¯æŒ WebCodecs API
}
```

# Web ç¼–è§£ç å™¨ API å‡ºç°çš„åŸå› 

ç°åœ¨å·²ç»æœ‰å¾ˆå¤š Web API è¿›è¡Œåª’ä½“æ“ä½œï¼š [Media Stream API](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API), [Media Recording API](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API), [Media Source API](https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API)ã€[WebRTC API](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API)ï¼Œä½†æ˜¯æ²¡æœ‰æä¾›ä¸€äº›åº•å±‚ API ç»™åˆ° Web å¼€å‘è€…è¿›è¡Œå¸§æ“ä½œæˆ–è€…å¯¹å·²ç»ç¼–ç çš„è§†é¢‘è¿›è¡Œè§£å°è£…æ“ä½œã€‚

å¾ˆå¤šéŸ³è§†é¢‘ç¼–è¾‘å™¨ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½¿ç”¨äº† WebAssembly æŠŠ[éŸ³è§†é¢‘ç¼–è§£ç ](https://en.wikipedia.org/wiki/Video_codec)å¸¦åˆ°äº†æµè§ˆå™¨ï¼Œä½†æ˜¯æœ‰ä¸ªé—®é¢˜æ˜¯ç°åœ¨çš„æµè§ˆå™¨å¾ˆå¤šå·²ç»åœ¨åº•å±‚æ”¯æŒäº†éŸ³è§†é¢‘ç¼–è§£ç ï¼Œå¹¶ä¸”è¿˜è¿›è¡Œäº†å¾ˆå¤šç¡¬ä»¶åŠ é€Ÿçš„è°ƒä¼˜ï¼Œå¦‚æœä½¿ç”¨ WebAssembly é‡æ–°æ‰“åŒ…è¿™äº›èƒ½åŠ›ï¼Œä¼¼ä¹æµªè´¹äººåŠ›å’Œè®¡ç®—æœºèµ„æºã€‚

æ‰€ä»¥å°±è¯ç”Ÿäº† [WebCodecs API](https://wicg.github.io/web-codecs/)ï¼Œæš´éœ²åª’ä½“ API æ¥ä½¿ç”¨æµè§ˆå™¨å·²ç»æœ‰çš„ä¸€äº›èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼š

- è§†é¢‘å’ŒéŸ³é¢‘è§£ç 
- è§†é¢‘å’ŒéŸ³é¢‘ç¼–ç 
- åŸå§‹è§†é¢‘å¸§
- å›¾åƒè§£ç å™¨

è¿™æ—¶å€™ä¸€äº› web åª’ä½“å¼€å‘é¡¹ç›®ä¾‹å¦‚è§†é¢‘ç¼–è¾‘å™¨ã€è§†é¢‘ä¼šè®®ã€è§†é¢‘æµçš„æ“ä½œå°±æ–¹ä¾¿å¤šäº†

é¡¹ç›®è¿›å±•æŸ¥çœ‹ï¼šhttps://github.com/WICG/web-codecs

# WebCodecs å¤„ç†æµç¨‹

`frames` æ˜¯è§†é¢‘å¤„ç†çš„æ ¸å¿ƒï¼Œå› æ­¤ WebCodecs å¤§å¤šæ•°ç±»è¦ä¹ˆæ¶ˆè€— `frames` è¦ä¹ˆç”Ÿäº§ `frames`ã€‚Video encoders æŠŠ `frames` è½¬æ¢ä¸º `encoded chunks`ï¼ŒVideo Decoders æŠŠ `encoded chunks` è½¬æ¢ä¸º `frames`ã€‚è¿™ä¸€åˆ‡éƒ½åœ¨éä¸»çº¿ç¨‹å¼‚æ­¥å¤„ç†ï¼Œæ‰€ä»¥å¯ä»¥ä¿è¯ä¸»çº¿ç¨‹é€Ÿåº¦ã€‚

å½“å‰ï¼Œåœ¨ WebCodecs ä¸­ï¼Œåœ¨é¡µé¢ä¸Šæ˜¾ç¤º `frame` çš„å”¯ä¸€æ–¹æ³•æ˜¯å°†å…¶è½¬æ¢ä¸º [ImageBitmap](https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap) å¹¶åœ¨ canvas ä¸Šç»˜åˆ¶ä½å›¾æˆ–å°†å…¶è½¬æ¢ä¸º [WebGLTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLTexture)

# Webcodecs å®é™…åº”ç”¨

## Encoding

ç°åœ¨æœ‰ä¸¤ç§æ–¹æ³•æŠŠå·²ç»å­˜åœ¨çš„å›¾ç‰‡è½¬æ¢ä¸º `VideoFrame`

- ä¸€ç§æ˜¯é€šè¿‡ [ImageBitmap](https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap) åˆ›å»º frame
- ç¬¬äºŒç§æ˜¯é€šè¿‡ `VideoTrackReader` è®¾ç½®æ–¹æ³•æ¥å¤„ç†ä» `[MediaStreamTrack](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack)` äº§ç”Ÿçš„ frameï¼Œå½“éœ€è¦ä»æ‘„åƒæœºæˆ–å±å¹•æ•è·è§†é¢‘æµæ—¶ï¼Œè¿™ä¸ª API å¾ˆæœ‰ç”¨

### ImageBitmap

![01.png](https://cdn-1257430323.cos.ap-guangzhou.myqcloud.com/assets/imgs/20210429091535_d1c49c49839de8210cf326cc6d8ef22c.png)

```js
let cnv = document.createElement('canvas');
// draw something on the canvas
...
let bitmap = await createImageBitmap(cnv);
let frameFromBitmap = new VideoFrame(bitmap, { timestamp: 0 });
```

ç¬¬ä¸€ç§æ˜¯ç›´æ¥ä» ImageBitmap åˆ›å»º frameã€‚åªéœ€è°ƒç”¨ `new VideoFrame()` æ„é€ å‡½æ•°å¹¶ä¸ºå…¶æä¾› bitmap å’Œå±•ç¤ºæ—¶é—´æˆ³

### VideoTrackReader

![02.png](https://cdn-1257430323.cos.ap-guangzhou.myqcloud.com/assets/imgs/20210429091550_382ee962dab29bef0dd8d5699e036c95.png)

```js
const framesFromStream = [];
const stream = await navigator.mediaDevices.getUserMedia({ â€¦ });
const vtr = new VideoTrackReader(stream.getVideoTracks()[0]);
vtr.start((frame) => {
  framesFromStream.push(frame);
});
```

ä½¿ç”¨ VideoEncoder å°† frame ç¼–ç ä¸º EncodedVideoChunk å¯¹è±¡ï¼ŒVideoEncoder éœ€è¦ä¸¤ä¸ªå¯¹è±¡ï¼š

- å¸¦æœ‰ `output` å’Œ `error` ä¸¤ä¸ªæ–¹æ³•çš„åˆå§‹åŒ–å¯¹è±¡ï¼Œä¼ é€’ç»™ `VideoEncoder` åæ— æ³•ä¿®æ”¹
- Encoder é…ç½®å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«è¾“å‡ºè§†é¢‘æµçš„å‚æ•°ã€‚å¯ä»¥ç¨åé€šè¿‡è°ƒç”¨ `configure()` æ¥æ›´æ”¹è¿™äº›å‚æ•°

```js
const init = {
  output: handleChunk,
  error: (e) => {
    console.log(e.message);
  }
};

let config = {
  codec: 'vp8',
  width: 640,
  height: 480,
  bitrate: 8_000_000, // 8 Mbps
  framerate: 30,
};

let encoder = new VideoEncoder(init);
encoder.configure(config);
```

è®¾ç½®å¥½ encoder åï¼Œå¯ä»¥æ¥å— frames äº†ï¼Œå½“å¼€å§‹ä» media stream æ¥å— frames çš„æ—¶å€™ï¼Œä¼ é€’ç»™ `VideoTrackReader.start()` çš„ callback å°±ä¼šè¢«æ‰§è¡Œï¼ŒæŠŠ frame ä¼ é€’ç»™ encoderï¼Œéœ€è¦å®šæ—¶æ£€æŸ¥ frame é˜²æ­¢è¿‡å¤šçš„ frames å¯¼è‡´å¤„ç†é—®é¢˜ã€‚æ³¨æ„ï¼š`encoder.configure()` å’Œ `encoder.encode()` ä¼šç«‹å³è¿”å›ï¼Œä¸ä¼šç­‰å¾…çœŸæ­£å¤„ç†å®Œæˆã€‚å¦‚æœå¤„ç†å®Œæˆ `output()`æ–¹æ³•ä¼šè¢«è°ƒç”¨ï¼Œå…¥å‚æ˜¯ `encoded chunk`ã€‚å†æ³¨æ„ï¼š`encoer.encode()` ä¼šæ¶ˆè€—æ‰ frameï¼Œå¦‚æœ frame éœ€è¦åé¢ä½¿ç”¨ï¼Œéœ€è¦è°ƒç”¨ `clone` æ¥å¤åˆ¶å®ƒã€‚

```js
let frameCounter = 0;
let pendingOutputs = 0;
const vtr = new VideoTrackReader(stream.getVideoTracks()[0]);

vtr.start((frame) => {
  if (pendingOutputs > 30) {
    // æœ‰å¤ªå¤šå¸§æ­£åœ¨å¤„ç†ä¸­ï¼Œç¼–ç å™¨æ‰¿å—ä¸è¿‡æ¥ï¼Œä¸æ·»åŠ æ–°çš„å¤„ç†å¸§äº†
    return;
  }
  frameCounter++;
  pendingOutputs++;
  const insert_keyframe = frameCounter % 150 === 0;
  encoder.encode(frame, { keyFrame: insert_keyframe });
});
```

æœ€åå°±æ˜¯å®Œæˆ handleChunk æ–¹æ³•ï¼Œé€šå¸¸ï¼Œæ­¤åŠŸèƒ½æ˜¯é€šè¿‡ç½‘ç»œå‘é€æ•°æ®å—æˆ–å°†å®ƒä»¬å°è£…åˆ°åˆ°åª’ä½“å®¹å™¨ä¸­

```js
function handleChunk(chunk) {
  let data = new Uint8Array(chunk.data);  // actual bytes of encoded data
  let timestamp = chunk.timestamp;        // media time in microseconds
  let is_key = chunk.type == 'key';       // can also be 'delta'
  pending_outputs--;
  fetch(`/upload_chunk?timestamp=${timestamp}&type=${chunk.type}`,
  {
    method: 'POST',
    headers: { 'Content-Type': 'application/octet-stream' },
    body: data
  });
}
```

æœ‰æ—¶å€™éœ€è¦ç¡®ä¿æ‰€æœ‰ pending çš„ encoding è¯·æ±‚å®Œæˆï¼Œè°ƒç”¨ `flush()`

```js
await encoder.flush();
```

## Decoding

è®¾ç½® `VideoDecoder` å’Œä¸Šé¢ç±»ä¼¼ï¼Œéœ€è¦ä¼ é€’ `init` å’Œ `config` ä¸¤ä¸ªå¯¹è±¡

```js
const init = {
  output: handleFrame,
  error: (e) => {
    console.log(e.message);
  },
};

const config = {
  codec: "vp8",
  codedWidth: 640,
  codedHeight: 480,
};

const decoder = new VideoDecoder(init);
decoder.configure(config);
```

è®¾ç½®å¥½ `decoder` ä¹‹åå°±å¯ä»¥ç»™å®ƒå–‚ `EncodedVideoChunk` å¯¹è±¡äº†ï¼Œé€šè¿‡ `[BufferSouce](https://developer.mozilla.org/en-US/docs/Web/API/BufferSource)` æ¥åˆ›å»º `chunk`

```js
const responses = await downloadVideoChunksFromServer(timestamp);
for (let i = 0; i < responses.length; i++) {
  const chunk = new EncodedVideoChunk({
    timestamp: responses[i].timestamp,
    data: new Uint8Array(responses[i].body),
  });
  decoder.decode(chunk);
}
await decoder.flush();

```

![03.png](https://cdn-1257430323.cos.ap-guangzhou.myqcloud.com/assets/imgs/20210429091610_1495b150a15d1fcdc5becf9f90cbbdb9.png)

æ¸²æŸ“ `decoded frame` åˆ°é¡µé¢ä¸Šåˆ†ä¸ºä¸‰æ­¥ï¼š

- æŠŠ `VideoFrame` è½¬æ¢ä¸º `[ImageBitmap](https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap)`
- ç­‰å¾…åˆé€‚çš„æ—¶æœºæ˜¾ç¤º frame
- å°† image ç”»åˆ° canvas ä¸Š

å½“ä¸€ä¸ª frame ä¸å†éœ€è¦çš„æ—¶å€™ï¼Œè°ƒç”¨ `destroy()` åœ¨åƒåœ¾å›æ”¶ä¹‹å‰æ‰‹åŠ¨é”€æ¯ä»–ï¼Œè¿™å¯ä»¥å‡å°‘é¡µé¢å†…å­˜å ç”¨

```js
const cnv = document.getElementById("canvas_to_render");
const ctx = cnv.getContext("2d", { alpha: false });
const readyFrames = [];
let underflow = true;
let timeBase = 0;

function handleFrame(frame) {
  readyFrames.push(frame);
  if (underflow) setTimeout(renderFrame, 0);
}

function delay(time_ms) {
  return new Promise((resolve) => {
    setTimeout(resolve, time_ms);
  });
}

function calculateTimeTillNextFrame(timestamp) {
  if (timeBase == 0) timeBase = performance.now();
  const media_time = performance.now() - timeBase;
  return Math.max(0, timestamp / 1000 - media_time);
}

async function renderFrame() {
  if (readyFrames.length === 0) {
    underflow = true;
    return;
  }
  const frame = readyFrames.shift();
  underflow = false;

  const bitmap = await frame.createImageBitmap();
  frame.destroy();
  // æ ¹æ®å¸§çš„æ—¶é—´æˆ³ï¼Œè®¡ç®—åœ¨æ˜¾ç¤ºä¸‹ä¸€å¸§ä¹‹å‰éœ€è¦çš„å®æ—¶ç­‰å¾…æ—¶é—´
  const timeTillNextFrame = calculateTimeTillNextFrame(frame.timestamp);
  await delay(timeTillNextFrame);
  ctx.drawImage(bitmap, 0, 0);

  // ç«‹å³ä¸‹ä¸€å¸§æ¸²æŸ“
  setTimeout(renderFrame, 0);
}
```

## Demo

ä½“éªŒåœ°å€ï¼šhttps://ringcrl.github.io/static/webcodecs-demo/

å¦‚æœæ‰“ä¸å¼€å‚è€ƒä¸Šé¢ã€åœ¨ Chrome >= 86 çš„ç‰ˆæœ¬è¿›è¡Œä½“éªŒã€‘

```html
<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <style>
    canvas {
      padding: 10px;
      background: gold;
    }

    button {
      background-color: #555555;
      border: none;
      color: white;
      padding: 15px 32px;
      width: 150px;
      text-align: center;
      display: block;
      font-size: 16px;
    }
  </style>
</head>

<body>
  <button onclick="playPause()">Pause</button>
  <canvas id="dst" width="640" height="480"></canvas>
  <canvas style="visibility: hidden;" id="src" width="640" height="480"></canvas>
  <script src="./main.js"></script>

</body>

</html>
```

```js
const codecString = "vp8";
let keepGoing = true;

function playPause() {
  keepGoing = !keepGoing;
  const btn = document.querySelector("button");
  if (keepGoing) {
    btn.innerText = "Pause";
  } else {
    btn.innerText = "Play";
  }
}

function delay(time_ms) {
  return new Promise((resolve) => {
    setTimeout(resolve, time_ms);
  });
}

async function startDrawing() {
  const cnv = document.getElementById("src");
  const ctx = cnv.getContext("2d", { alpha: false });

  ctx.fillStyle = "white";
  const { width } = cnv;
  const { height } = cnv;
  const cx = width / 2;
  const cy = height / 2;
  const r = Math.min(width, height) / 5;
  const drawOneFrame = function drawOneFrame(time) {
    const angle = Math.PI * 2 * (time / 5000);
    const scale = 1 + 0.3 * Math.sin(Math.PI * 2 * (time / 7000));
    ctx.save();
    ctx.fillRect(0, 0, width, height);

    ctx.translate(cx, cy);
    ctx.rotate(angle);
    ctx.scale(scale, scale);

    ctx.font = "30px Verdana";
    ctx.fillStyle = "black";
    const text = "ğŸ˜ŠğŸ“¹ğŸ“·Hello WebCodecs ğŸ¥ğŸï¸ğŸ˜Š";
    const size = ctx.measureText(text).width;
    ctx.fillText(text, -size / 2, 0);
    ctx.restore();
    window.requestAnimationFrame(drawOneFrame);
  };
  window.requestAnimationFrame(drawOneFrame);
}

function captureAndEncode(processChunk) {
  const cnv = document.getElementById("src");
  const fps = 60;
  let pendingOutputs = 0;
  let frameCounter = 0;
  const stream = cnv.captureStream(fps);
  const vtr = new VideoTrackReader(stream.getVideoTracks()[0]);

  const init = {
    output: (chunk) => {
      pendingOutputs--;
      processChunk(chunk);
    },
    error: (e) => {
      console.log(e.message);
      vtr.stop();
    },
  };

  const config = {
    codec: codecString,
    width: cnv.width,
    height: cnv.height,
    bitrate: 10e6,
    framerate: fps,
  };

  const encoder = new VideoEncoder(init);
  encoder.configure(config);

  vtr.start((frame) => {
    if (!keepGoing) return;
    if (pendingOutputs > 30) {
      // Too many frames in flight, encoder is overwhelmed
      // let's drop this frame.
      return;
    }
    frameCounter++;
    pendingOutputs++;
    const insert_keyframe = frameCounter % 150 === 0;
    encoder.encode(frame, { keyFrame: insert_keyframe });
  });
}

async function frameToBitmapInTime(frame, timeout_ms) {
  const options = { colorSpaceConversion: "none" };
  const convertPromise = frame.createImageBitmap(options);

  if (timeout_ms <= 0) return convertPromise;

  const results = await Promise.all([convertPromise, delay(timeout_ms)]);
  return results[0];
}

function startDecodingAndRendering() {
  const cnv = document.getElementById("dst");
  const ctx = cnv.getContext("2d", { alpha: false });
  const readyFrames = [];
  let underflow = true;
  let timeBase = 0;

  function calculateTimeTillNextFrame(timestamp) {
    if (timeBase === 0) timeBase = performance.now();
    const mediaTime = performance.now() - timeBase;
    return Math.max(0, timestamp / 1000 - mediaTime);
  }

  async function renderFrame() {
    if (readyFrames.length === 0) {
      underflow = true;
      return;
    }
    const frame = readyFrames.shift();
    underflow = false;

    const bitmap = await frame.createImageBitmap();
    // æ ¹æ®å¸§çš„æ—¶é—´æˆ³ï¼Œè®¡ç®—åœ¨æ˜¾ç¤ºä¸‹ä¸€å¸§ä¹‹å‰éœ€è¦çš„å®æ—¶ç­‰å¾…æ—¶é—´
    const timeTillNextFrame = calculateTimeTillNextFrame(frame.timestamp);
    await delay(timeTillNextFrame);
    ctx.drawImage(bitmap, 0, 0);

    // ç«‹å³ä¸‹ä¸€å¸§æ¸²æŸ“
    setTimeout(renderFrame, 0);
    frame.destroy();
  }

  function handleFrame(frame) {
    readyFrames.push(frame);
    if (underflow) {
      underflow = false;
      setTimeout(renderFrame, 0);
    }
  }

  const init = {
    output: handleFrame,
    error: (e) => {
      console.log(e.message);
    },
  };

  const config = {
    codec: codecString,
    codedWidth: cnv.width,
    codedHeight: cnv.height,
  };

  const decoder = new VideoDecoder(init);
  decoder.configure(config);
  return decoder;
}

function main() {
  if (!("VideoEncoder" in window)) {
    document.body.innerHTML = "<h1>WebCodecs API is not supported.</h1>";
    return;
  }
  startDrawing();
  const decoder = startDecodingAndRendering();
  captureAndEncode((chunk) => {
    decoder.decode(chunk);
  });
}

document.body.onload = main;
```

# å‚è€ƒåœ°å€

[Video processing with WebCodecs](https://web.dev/webcodecs/)
